{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busquedas semanticas y RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la base de datos vectorial podemos brindar al modelo información adicional para que responda según el mejor contexto posible, esto nos ayuda a que el modelo responda con datos con los que no fue entrando y que la ventana de contexto no sea tan grande y sin información innecesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import chromadb\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el cliente para acceder al modelo generador de texto LLM\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuración\n",
    "EMBEDDINGS_DIR = \"../data/03_embeddings/\"\n",
    "DB_NAME = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "LLM_MODEL = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=EMBEDDINGS_DIR)\n",
    "collection = chroma_client.get_or_create_collection(DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener embeddings\n",
    "def get_embedding(text):\n",
    "    \"\"\"Obtiene el embedding de un texto usando OpenAI.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\" #text-embedding-ada-002\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar la busqueda semantica \n",
    "# Esta metodologia compara el embedding generado con el texto de entrada (prompt) con los embeddings que estan en la base\n",
    "# Buscando los más similares entre si mediante la similitud del coseno\n",
    "def search_documents_with_model(query, k=15):\n",
    "    \"\"\"Realiza una búsqueda en la base de datos vectorial utilizando un modelo específico para la consulta.\"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=k)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar respuestas con RAG\n",
    "# Ya con el texto de los chunks con información más relevantes podemos usarlos como contexto para que el modelo\n",
    "# Responda de manera correcta\n",
    "def generate_rag_response(query, k=15):\n",
    "    \"\"\"Recupera documentos relevantes y genera una respuesta con el LLM.\"\"\"\n",
    "    relevant_docs = search_documents_with_model(query, k)\n",
    "    context = \"\\n\".join([doc for doc in relevant_docs['documents'][0]])\n",
    "    prompt = f\"\"\"\n",
    "    Usa la siguiente información para responder la pregunta:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    Pregunta: {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Eres un asistente virtual de la compañia de financiamiento Tuya S.A\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta generada:\n",
      "Las tarjetas de crédito disponibles de Tuya S.A son:\n",
      "\n",
      "1. Tarjeta Éxito\n",
      "2. Tarjeta Carulla\n",
      "3. Tarjeta Éxito Pro Mastercard\n",
      "4. Tarjeta Éxito Gold Mastercard\n",
      "5. Tarjeta Carulla Gold Mastercard\n",
      "6. Tarjeta Carulla Mastercard Black\n",
      "7. Tarjeta Club del Comerciante Mastercard\n",
      "8. Tarjeta Éxito Digital Mastercard\n",
      "\n",
      "Por favor, ten en cuenta que la disponibilidad de estas tarjetas puede variar y es recomendable verificar la información actualizada en el sitio web oficial de Tuya S.A.\n"
     ]
    }
   ],
   "source": [
    "# Prueba de búsqueda y generación\n",
    "# Pregunta 1 requerida en la prueba tecnica\n",
    "def test_rag():\n",
    "    query = \"¿ Cuáles son los nombres de las tarjetas que tiene disponibles Tuya S.A?.\"\n",
    "    response = generate_rag_response(query)\n",
    "    print(\"Respuesta generada:\")\n",
    "    print(response)\n",
    "\n",
    "# Ejecutar prueba\n",
    "test_rag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta generada:\n",
      "El producto Credicompras tiene diferentes tasas de interés y pólizas dependiendo del tipo de crédito. Para el Credicompras Dirigido y Credicompras Libre Destino, la Tasa Efectiva Anual es de 24,89805% y la póliza colectiva de seguro de deudores es de 3.143. Para el Credicompras Bajo Monto, la Tasa Efectiva Anual es de 56,08602% y la póliza colectiva de seguro de deudores también es de 3.143.\n"
     ]
    }
   ],
   "source": [
    "# Prueba de búsqueda y generación\n",
    "# Pregunta 2 requerida en la prueba tecnica\n",
    "def test_rag():\n",
    "    query = \"¿ Cuáles son los valores la tasa de interés y póliza del producto credicompras?.\"\n",
    "    response = generate_rag_response(query)\n",
    "    print(\"Respuesta generada:\")\n",
    "    print(response)\n",
    "\n",
    "# Ejecutar prueba\n",
    "test_rag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prueba_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
