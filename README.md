# ğŸ“š RAG con LLMs - Proyecto de BÃºsqueda SemÃ¡ntica

Este repositorio contiene un sistema de **Retrieval-Augmented Generation (RAG)** utilizando **OpenAI embeddings y ChromaDB** para mejorar la generaciÃ³n de respuestas en lenguaje natural.

## ğŸš€ CaracterÃ­sticas

âœ” Procesamiento de documentos `.txt`  
âœ” GeneraciÃ³n y almacenamiento de embeddings en **ChromaDB**  
âœ” RecuperaciÃ³n de documentos relevantes con bÃºsqueda semÃ¡ntica  
âœ” GeneraciÃ³n de respuestas usando **GPT-4**  
âœ” CÃ³digo modular en Python con notebooks para experimentaciÃ³n  


## ğŸ›  InstalaciÃ³n

**1ï¸âƒ£ Clonar el repositorio**
git clone https://github.com/tu-usuario/rag-llm-project.git
cd rag-llm-project


**2ï¸âƒ£ Crear un entorno virtual (opcional)**
python -m venv env
source env/bin/activate  # En macOS/Linux
env\Scripts\activate  # En Windows

**3ï¸âƒ£ Instalar dependencias**
pip install -r requirements.txt

**4ï¸âƒ£ Configurar variables de entorno**
OPENAI_API_KEY=tu_api_key_aqui

ğŸš€ Uso
Ejecutar el pipeline RAG
Para hacer una consulta y obtener las respuestas requeridas en la prueba:
python src/main.py

ğŸ— TecnologÃ­as utilizadas
Python 3.8+
OpenAI API (text-embedding-ada-002, gpt-4)
ChromaDB (Base de datos vectorial)
FAISS (Alternativa para almacenamiento de embeddings)
Jupyter Notebook (AnÃ¡lisis y pruebas)

ğŸ‘¨â€ğŸ’» Autor
JUAN CARLOS CABRERA MUÃ‘OZ
ğŸ“§ jcarloscm9312@gmail.com




